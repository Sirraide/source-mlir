#include <llvm/Support/OptimizedStructLayout.h>
#include <mlir/Dialect/Arith/IR/Arith.h>
#include <mlir/Dialect/ControlFlow/IR/ControlFlow.h>
#include <mlir/Dialect/ControlFlow/IR/ControlFlowOps.h>
#include <mlir/Dialect/Func/IR/FuncOps.h>
#include <mlir/Dialect/LLVMIR/LLVMDialect.h>
#include <mlir/IR/Builders.h>
#include <source/CG/CodeGen.hh>
#include <source/Core.hh>
#include <source/Frontend/AST.hh>
#include <source/HLIR/HLIRDialect.hh>

namespace src {
struct CodeGen {
    Module* const mod;
    Context* const ctx;
    mlir::MLIRContext* mctx;
    mlir::OpBuilder builder;
    bool no_verify;

    mlir::Type Int, Bool;

    /// External procedures that we have already declared.
    DenseMap<StringRef, hlir::FuncOp> declared_procedures;

    /// Autogenerated dtors/ctors.
    DenseMap<Expr*, StringRef, TypeBase::DenseMapInfo> destructors;
    DenseMap<Expr*, StringRef, TypeBase::DenseMapInfo> constructors;

    /// These should not be emitted multiple times.
    DenseMap<LocalDecl*, mlir::Value> local_vars;
    DenseMap<DeferExpr*, hlir::DeferOp> defers;

    /// Captured locals pointer for procedures.
    DenseMap<ProcDecl*, mlir::Value> captured_locals_ptrs;

    /// Cached types.
    DenseMap<RecordType*, mlir::Type> record_types;

    /// Emitted string literals.
    StringMap<hlir::StringOp> string_literals;

    /// Procedure weâ€™re currently emitting.
    ProcDecl* curr_proc{};

    CodeGen(mlir::MLIRContext* mctx, Module* mod, bool no_verify)
        : mod(mod),
          ctx(mod->context),
          mctx(mctx),
          builder(mctx),
          no_verify(no_verify) {
        Int = GetIntType(Type::Int.size(ctx));
        Bool = GetIntType(Size::Bits(1));
    }

    CodeGen(const CodeGen&) = delete;
    CodeGen(CodeGen&&) = delete;
    CodeGen& operator=(const CodeGen&) = delete;
    CodeGen& operator=(CodeGen&&) = delete;

    /// Create an alloca for a local variable.
    void AllocateLocalVar(LocalDecl* decl);

    /// Attach a block to the end of a region.
    auto Attach(mlir::Region* region, mlir::Block* block) -> mlir::Block*;

    /// Check if a block is closed.
    bool Closed();
    bool Closed(mlir::Block* block);

    /// Construct an object at an address.
    void Construct(
        mlir::Location loc,
        mlir::Value addr,
        Align align,
        ConstructExpr* ctor
    );
    /*
        /// Get the (mangled) name of the constructor of a type.
        auto ScopedPointerCtor(Expr* type) -> std::optional<StringRef>;*/

    /// Convert CC to LLVM CC.
    auto ConvertCC(CallConv cc) -> mlir::LLVM::CConv;

    template <typename T, typename... Args>
    auto Create(mlir::Location loc, Args&&... args) -> decltype(builder.create<T>(loc, std::forward<Args>(args)...));

    auto CreateInt(mlir::Location loc, u64 value) -> mlir::Value;
    auto CreateInt(mlir::Location loc, const APInt& value, Type type) -> mlir::Value;

    /// Create a function and execute a callback to populate its body.
    template <typename Callable>
    auto CreateProcedure(
        mlir::FunctionType type,
        StringRef name,
        CallConv cc,
        Linkage linkage,
        bool smf,
        Callable callable
    );

    /// Create an external function.
    void CreateExternalProcedure(mlir::FunctionType type, StringRef name, CallConv cc);

    /// Create a slice from an array lvalue.
    auto CreateSliceFromArray(
        mlir::Location loc,
        ArrayType* type,
        mlir::Value array
    ) -> hlir::LiteralOp;

    /// Destroy an object at an address.
    auto Destroy(mlir::Location loc, mlir::Value addr, Type type) -> mlir::Value;

    /// Get the (mangled) name of the destructor of a type.
    auto Destructor(Type type) -> std::optional<StringRef>;

    auto EmitReference(mlir::Location loc, Expr* decl) -> mlir::Value;

    auto EndLifetime(LocalDecl* decl);

    template <typename Op>
    [[nodiscard]] auto GenerateAssignBinOp(BinaryExpr* b) -> mlir::Value;

    template <typename Op>
    [[nodiscard]] auto GenerateBinOp(BinaryExpr* b) -> mlir::Value;

    template <typename Op>
    [[nodiscard]] auto GenerateCmpOp(BinaryExpr* b) -> mlir::Value;

    [[nodiscard]] auto GenerateConvertingCast(CastExpr* cast, mlir::Value operand) -> mlir::Value;

    [[nodiscard]] auto Generate(Expr* expr) -> mlir::Value;
    void GenerateModule();
    void GenerateProcedure(ProcDecl* proc);

    /// Get an integer type.
    auto GetIntType(Size width) -> mlir::IntegerType;

    /// Retrieve the static chain pointer for a procedure.
    auto GetStaticChainPointer(ProcDecl* proc) -> mlir::Value;

    /// Perform preprocessing on locals to support nested procedures.
    void InitStaticChain(ProcDecl* proc, hlir::FuncOp f);

    /// Get the MLIR location of a source location.
    auto Loc(Location loc) -> mlir::Location;

    /// Offset a pointer by a constant.
    auto Offset(mlir::Value ptr, i64 value) -> mlir::Value;

    auto Ty(Type type, bool for_closure = false) -> mlir::Type;

    /// Generate a set of operations to unwind from expressions that need unwinding.
    auto UnwindValues(ArrayRef<Expr*> exprs) -> SmallVector<mlir::Value>;
};
} // namespace src

void src::CodeGenModule(mlir::MLIRContext* threads, src::Module* mod, bool no_verify) {
    Assert(not mod->context->has_error(), "Refusing to codegen broken module");
    CodeGen c{threads, mod, no_verify};
    c.GenerateModule();
}

/// ===========================================================================
///  Helpers
/// ===========================================================================
auto src::CodeGen::Loc(Location loc) -> mlir::Location {
    if (not loc.seekable(ctx)) return mlir::UnknownLoc::get(mctx);
    auto lc = loc.seek_line_column(ctx);
    return mlir::FileLineColLoc::get(
        mctx,
        ctx->file(loc.file_id)->path().string(),
        unsigned(lc.line),
        unsigned(lc.col)
    );
}

void src::Module::print_hlir(bool use_generic_assembly_format) const {
    mlir::OpPrintingFlags flags;
    flags.printGenericOpForm(use_generic_assembly_format);
    if (not use_generic_assembly_format) flags.assumeVerified();
    cast<mlir::ModuleOp>(mlir_module_op)->print(llvm::outs(), flags);
}

mlir::ModuleOp src::Module::_mlir() {
    return cast<mlir::ModuleOp>(mlir_module_op);
}

void src::CodeGen::AllocateLocalVar(LocalDecl* decl) {
    if (local_vars.contains(decl)) return;

    /// Captured variables are stored in the static chain area.
    if (decl->captured) {
        local_vars[decl] = Create<hlir::StructGEPOp>(
            Loc(decl->location),
            captured_locals_ptrs.at(decl->parent),
            decl->capture_index
        );
    } else {
        local_vars[decl] = Create<hlir::LocalOp>(
            Loc(decl->location),
            Ty(decl->type),
            decl->type.align(ctx).value(),
            decl->deleted_or_moved
        );
    }
}

auto src::CodeGen::Attach(mlir::Region* region, mlir::Block* block) -> mlir::Block* {
    region->getBlocks().insert(region->end(), block);
    return block;
}

bool src::CodeGen::Closed() {
    return Closed(builder.getBlock());
}

auto ConvertLinkage(src::Linkage l) -> mlir::LLVM::Linkage {
    using L = mlir::LLVM::Linkage;
    switch (l) {
        case src::Linkage::Local:
        case src::Linkage::Internal:
            return L::Private;

        case src::Linkage::Imported:
        case src::Linkage::Exported:
        case src::Linkage::Reexported:
            return L::External;

        case src::Linkage::LinkOnceODR:
            return L::LinkonceODR;
    }
}

template <typename Callable>
auto src::CodeGen::CreateProcedure(
    mlir::FunctionType type,
    StringRef name,
    CallConv cc,
    Linkage linkage,
    bool smf,
    Callable callable
) {
    mlir::OpBuilder::InsertionGuard guard{builder};
    builder.setInsertionPointToEnd(mod->mlir.getBody());
    auto func = Create<hlir::FuncOp>(
        builder.getUnknownLoc(),
        name,
        ConvertLinkage(linkage),
        ConvertCC(cc),
        type,
        smf,
        false
    );

    builder.setInsertionPointToEnd(&func.getBody().front());
    return std::invoke(std::forward<Callable>(callable), func);
}

void src::CodeGen::CreateExternalProcedure(mlir::FunctionType type, StringRef name, CallConv cc) {
    if (declared_procedures.contains(name)) return;
    CreateProcedure(type, name, cc, Linkage::Imported, false, [&](hlir::FuncOp proc) {
        proc.eraseBody();
        proc.setPrivate();
        declared_procedures[proc.getName()] = proc;
    });
}

auto src::CodeGen::CreateSliceFromArray(
    mlir::Location loc,
    ArrayType* type,
    mlir::Value array
) -> hlir::LiteralOp {
    /// Operand is an lvalue, so array decay to retrieve the pointer works.
    auto ptr = Create<hlir::ArrayDecayOp>(loc, array);
    auto size = CreateInt(loc, type->dimension(), Type::Int);
    return Create<hlir::LiteralOp>(
        loc,
        hlir::SliceType::get(ptr.getType().getElem()),
        ptr,
        size
    );
}

bool src::CodeGen::Closed(mlir::Block* block) {
    return not block->empty() and block->back().hasTrait<mlir::OpTrait::IsTerminator>();
}

void src::CodeGen::Construct(
    mlir::Location loc,
    mlir::Value addr,
    Align align,
    ConstructExpr* ctor
) {
    auto args = ctor->args();

    /// Constructors that only construct an entire array take a
    /// pointer to the array, not a pointer to an element, so we
    /// need to decay the pointer in that case.
    auto LowerElemPtr = [&] {
        while (
            ctor->array_ctor() and
            isa<hlir::ArrayType>(cast<hlir::ReferenceType>(addr.getType()).getElem())
        ) addr = Create<hlir::ArrayDecayOp>(loc, addr);
    };

    switch (ctor->ctor_kind) {
        /// Handled elsewhere. No-op here.
        case ConstructKind::Parameter:
            break;

        /// Perform no initialisation at all.
        case ConstructKind::Uninitialised: break;

        /// Zero-initialisation is accomplished by creating a ConstructOp
        /// with no arguments other than the object itself.
        case ConstructKind::Zeroinit:
        case ConstructKind::ArrayZeroinit: {
            LowerElemPtr();
            Create<hlir::ConstructOp>(
                loc,
                addr,
                mlir::ValueRange{},
                ctor->elems()
            );
        } break;

        /// A trivial copy is always one argument.
        case ConstructKind::TrivialCopy:
        case ConstructKind::ArrayBroadcast: {
            Assert(args.size() == 1);
            LowerElemPtr();
            Create<hlir::ConstructOp>(
                loc,
                addr,
                Generate(args.front()),
                ctor->elems()
            );
        } break;

        /// Create a slice from a reference+size.
        case ConstructKind::SliceFromParts: {
            Assert(args.size() == 2);
            auto data = Generate(args[0]);
            auto size = Generate(args[1]);
            auto slice = Create<hlir::LiteralOp>(
                loc,
                hlir::SliceType::get(Ty(cast<ReferenceType>(args[0]->type)->elem)),
                data,
                size
            );

            Create<hlir::StoreOp>(
                loc,
                addr,
                slice,
                align.value()
            );
        } break;

        case ConstructKind::InitialiserCall:
        case ConstructKind::ArrayInitialiserCall: {
            SmallVector<mlir::Value> arguments;
            for (auto a : args) arguments.push_back(Generate(a));
            LowerElemPtr();
            Create<hlir::ConstructOp>(
                loc,
                addr,
                ctor->init()->mangled_name,
                arguments,
                ctor->elems()
            );
        } break;

        case ConstructKind::ArrayListInit: {
            addr = Create<hlir::ArrayDecayOp>(loc, addr);
            for (auto [i, c] : llvm::enumerate(ctor->args())) Construct(
                loc,
                Offset(addr, i64(i)),
                align,
                cast<ConstructExpr>(c)
            );
        } break;

        case ConstructKind::RecordListInit: {
            for (auto [f, c] : vws::zip(ctor->record_type()->non_padding_fields(), ctor->args())) {
                auto ptr = Create<hlir::StructGEPOp>(
                    loc,
                    addr,
                    f->index
                );

                Construct(
                    loc,
                    ptr,
                    f->type.align(ctx),
                    cast<ConstructExpr>(c)
                );
            }
        } break;
    }
}

/*auto src::CodeGen::Constructor(Expr* type) -> std::optional<StringRef> {
    if (not isa<ScopedPointerType>(type)) return std::nullopt;

    /// Auto-generate constructors for scoped pointers.
    if (auto sc = cast<ScopedPointerType>(type)) {
        if (auto d = constructors.find(sc); d != constructors.end())
            return d->second;

        /// Create a new function.
        ///
        /// A constructor always takes a reference to the type being constructed.
        auto fty = mlir::FunctionType::get(mctx, hlir::ReferenceType::get(Ty(sc)), {});
        auto name = fmt::format("_SK{}", sc.mangled_name(ctx));
        auto proc = CreateProcedure(fty, name, Linkage::LinkOnceODR, [&](hlir::FuncOp f) {
            /// Allocate the pointer.
            auto ptr = Create<hlir::NewOp>(
                builder.getUnknownLoc(),
                hlir::ReferenceType::get(Ty(sc->elem))
            );

            /// Store it in the reference.
            Create<hlir::StoreOp>(
                builder.getUnknownLoc(),
                f.getArgument(0),
                ptr.getResult(),
                sc.align(mod) / 8
            );

            /// Call the element typeâ€™s constructor, if any.
            Construct(builder.getUnknownLoc(), ptr.getResult(), sc->elem);

            /// Done.
            Create<hlir::ReturnOp>(builder.getUnknownLoc());
            return f;
        });

        /// Save it for later.
        return constructors[sc] = proc.getName();
    }

    Unreachable();
}*/

auto src::CodeGen::ConvertCC(CallConv cc) -> mlir::LLVM::CConv {
    switch (cc) {
        case CallConv::Native: return mlir::LLVM::CConv::C;
        case CallConv::Source: return mlir::LLVM::CConv::Fast;
    }

    Unreachable();
}

template <typename T, typename... Args>
auto src::CodeGen::Create(mlir::Location loc, Args&&... args) -> decltype(builder.create<T>(loc, std::forward<Args>(args)...)) {
    if (auto b = builder.getBlock(); not b->empty() and b->back().hasTrait<mlir::OpTrait::IsTerminator>()) {
        /// If the block is already closed, create a new one, or
        /// simply drop the instruction if it is a terminator.
        if constexpr (T::template hasTrait<mlir::OpTrait::IsTerminator>()) return {};
        builder.createBlock(b->getParent());
    }

    /// Create the instruction.
    return builder.create<T>(loc, std::forward<Args>(args)...);
}

auto src::CodeGen::CreateInt(mlir::Location loc, const APInt& value, Type type) -> mlir::Value {
    type = type.desugared;

    /// Explicit-width integer types.
    if (auto int_ty = dyn_cast<IntType>(type)) {
        if (int_ty->size.bits() > 64) Todo("Create > 64 bit integer constant");
        return Create<mlir::arith::ConstantIntOp>(
            loc,
            value.getZExtValue(),
            mlir::IntegerType::get(mctx, unsigned(int_ty->size.bits()))
        );
    }

    /// `int` type.
    else if (type == Type::Int) {
        return Create<mlir::arith::ConstantOp>(
            loc,
            Ty(Type::Int),
            builder.getI64IntegerAttr(i64(value.getZExtValue()))
        );
    }

    /// Invalid.
    else { Unreachable("Cannot create an integer constant of type {}", type.str(true)); }
}

auto src::CodeGen::CreateInt(mlir::Location loc, u64 value) -> mlir::Value {
    return CreateInt(loc, APInt(64, value), Type::Int);
}

auto src::CodeGen::Destroy(mlir::Location loc, mlir::Value addr, Type type) -> mlir::Value {
    type = type.desugared;
    auto d = Destructor(type);
    if (not d.has_value()) return {};
    return Create<hlir::DestroyOp>(
        loc,
        addr,
        *d
    );
}

auto src::CodeGen::Destructor(Type type) -> std::optional<StringRef> {
    if (not isa<ScopedPointerType, StructType>(type)) return std::nullopt;

    /// Some structs may have a destructor.
    if (auto s = dyn_cast<StructType>(type))
        return s->deleter ? std::optional{s->deleter->mangled_name} : std::nullopt;

    /// Auto-generate destructors for scoped pointers.
    if (auto sc = dyn_cast<ScopedPointerType>(type)) {
        if (auto d = destructors.find(sc); d != destructors.end())
            return d->second;

        /// Create a new function.
        ///
        /// A destructor always takes a reference to the type being destroyed.
        auto fty = mlir::FunctionType::get(mctx, hlir::ReferenceType::get(Ty(sc)), {});
        auto name = fmt::format("_SY{}", Type(sc).mangled_name);
        auto EmitBody = [&](hlir::FuncOp f) {
            /// Load the pointer.
            auto ptr = Create<hlir::LoadOp>(builder.getUnknownLoc(), f.getImplicitThis());

            /// Call the element typeâ€™s destructor, if any.
            Destroy(builder.getUnknownLoc(), ptr.getResult(), sc->elem);

            /// Delete the pointer.
            Create<hlir::DeleteOp>(builder.getUnknownLoc(), ptr.getResult());

            /// Done.
            Create<hlir::ReturnOp>(builder.getUnknownLoc());
            return f;
        };

        auto proc = CreateProcedure(
            fty,
            name,
            CallConv::Source,
            Linkage::LinkOnceODR,
            true,
            EmitBody
        );

        /// Save it for later.
        return destructors[sc] = proc.getName();
    }

    Unreachable();
}

auto src::CodeGen::EmitReference([[maybe_unused]] mlir::Location loc, src::Expr* decl) -> mlir::Value {
    /// If the operand is a function, create a function constant.
    if (auto p = dyn_cast<ProcDecl>(decl)) return Create<mlir::func::ConstantOp>(
        loc,
        Ty(p->type),
        mlir::SymbolRefAttr::get(mctx, p->mangled_name)
    );

    /// If the operand is an enumerator, emit its value.
    if (auto e = dyn_cast<EnumeratorDecl>(decl)) return CreateInt(
        loc,
        cast<ConstExpr>(e->value)->value.as_int(),
        e->type
    );

    /// Sometimes, we may bind a value directly to a constant.
    if (auto c = dyn_cast<ConstExpr>(decl)) return CreateInt(
        loc,
        c->value.as_int(),
        c->type
    );

    Unreachable();
}

auto src::CodeGen::EndLifetime([[maybe_unused]] LocalDecl* decl) {
    Todo();
}

void src::CodeGen::InitStaticChain(ProcDecl* proc, hlir::FuncOp func) {
    if (proc->captured_locals.empty() and not proc->takes_static_chain) return;

    /// Collect all captured variables; static chain is first.
    SmallVector<llvm::OptimizedStructLayoutField, 10> captured;
    if (proc->takes_static_chain) captured.push_back({
        nullptr,
        8,              /// FIXME: Get size of pointer type from context.
        llvm::Align(8), /// FIXME: Get alignment of pointer type from context.
        0,
    });

    /// Add a field for each captured variable.
    for (auto v : proc->captured_locals) {
        captured.push_back({
            v,
            u64(v->type.size(ctx).bytes()),
            v->type.align(ctx),
            llvm::OptimizedStructLayoutField::FlexibleOffset,
        });
    }

    /// Optimise the layout.
    const auto [size, align] = llvm::performOptimizedStructLayout(captured);

    /// Combine the allocas to a struct type. Even though the offsets of
    /// all fields are known, we may still need to emit padding to align
    /// each field to its required offset since LLVM doesnâ€™t know anything
    /// about the offsets.
    SmallVector<FieldDecl*> fields;
    Size total_size;
    for (const auto& [i, var] : llvm::enumerate(captured)) {
        /// Zero is the static chain.
        if (proc->takes_static_chain and i == 0) {
            fields.push_back(new (mod) FieldDecl(
                "",
                new (mod) ReferenceType(proc->parent->captured_locals_type, {}),
                {},
                Size::Bytes(0),
                0,
                false
            ));

            total_size += Size::Bytes(8); /// FIXME: Get pointer alignment from context.
            continue;
        }

        /// Anything else is a captured local. Note: const_cast is
        /// safe here because we passed in non-const LocalDecl*â€™s
        /// above.
        auto v = static_cast<LocalDecl*>(const_cast<void*>(var.Id));
        v->capture_index = isz(i);

        /// Insert padding if required.
        if (total_size.bytes() != var.Offset) {
            v->capture_index++;
            fields.push_back(new (mod) FieldDecl(
                "",
                ArrayType::GetByteArray(mod, isz(usz(var.Offset) - total_size.bytes())),
                {},
                total_size,
                u32(-1), /// Weâ€™re past the point where this matters.
                true
            ));
        }

        total_size = Size::Bytes(var.Offset) + v->type.size(ctx);
        fields.push_back(new (mod) FieldDecl(
            "",
            v->type,
            {},
            Size::Bytes(var.Offset),
            u32(-1), /// Weâ€™re past the point where this matters.
            false
        ));
    }

    /// Create a struct type and finalise it.
    auto s = new (mod) StructType(mod, std::move(fields));

    /// The alignment and size are just set to what LLVMâ€™s algorithm told us
    /// they should be. In particular, we need *not* ensure that the size is
    /// a multiple of the alignment, as we will never have an array of these
    /// anyway.
    s->stored_alignment = align;
    s->stored_size = Size::Bytes(size);
    s->sema.set_done();

    /// Associate it with the procedure and create the vars area.
    proc->captured_locals_type = s;
    captured_locals_ptrs[proc] = Create<hlir::LocalOp>(
        builder.getUnknownLoc(),
        Ty(s),
        s->stored_alignment.value(),
        false
    );

    /// Save the parentâ€™s chain pointer if there is one.
    if (proc->takes_static_chain) {
        Assert(func.getNumArguments() == proc->params.size() + 1);

        /// Save the pointer.
        Create<hlir::StoreOp>(
            builder.getUnknownLoc(),
            captured_locals_ptrs.at(proc),
            func.getExplicitArgument(u32(proc->params.size())), /// (!)
            8                                                   /// FIXME: Get alignment of pointer type from context.
        );
    }
}

auto src::CodeGen::Offset(mlir::Value ptr, i64 value) -> mlir::Value {
    if (value == 0) return ptr;
    return Create<hlir::OffsetOp>(
        ptr.getLoc(),
        ptr,
        CreateInt(ptr.getLoc(), u64(value))
    );
}

auto src::CodeGen::GetIntType(Size width) -> mlir::IntegerType {
    return mlir::IntegerType::get(mctx, unsigned(width.bits()));
}

auto src::CodeGen::GetStaticChainPointer(ProcDecl* proc) -> mlir::Value {
    /// Current procedure.
    if (curr_proc == proc) {
        Assert(captured_locals_ptrs.contains(proc));
        return captured_locals_ptrs.at(proc);
    }

    /// Load the parentâ€™s chain pointer.
    mlir::Value chain = Create<hlir::ChainExtractLocalOp>(
        builder.getUnknownLoc(),
        captured_locals_ptrs.at(curr_proc),
        0
    );

    /// Walk up the stack till we reach the desired procedure.
    for (auto p = curr_proc->parent; p != proc; p = p->parent) {
        chain = Create<hlir::ChainExtractLocalOp>(
            builder.getUnknownLoc(),
            chain,
            0
        );
    }

    return chain;
}

auto src::CodeGen::Ty(Type type, bool for_closure) -> mlir::Type {
    Assert(isa<TypeBase>(type), "Type is not a Type");
    switch (type->kind) {
        case Expr::Kind::BuiltinType: {
            switch (cast<BuiltinType>(type)->builtin_kind) {
                using K = BuiltinTypeKind;
                case K::Void: return mlir::NoneType::get(mctx);
                case K::NoReturn: return mlir::NoneType::get(mctx);
                case K::Bool: return Bool;
                case K::Int: return Int;

                case K::ArrayLiteral:
                case K::MemberProc:
                case K::OverloadSet:
                case K::Unknown:
                    Unreachable();
            }
            Unreachable();
        }

        case Expr::Kind::IntType: {
            auto ty = cast<IntType>(type);
            return mlir::IntegerType::get(mctx, unsigned(ty->size.bits()));
        }

        case Expr::Kind::SliceType: {
            auto ty = cast<SliceType>(type);
            return hlir::SliceType::get(Ty(ty->elem));
        }

        case Expr::Kind::ReferenceType:
        case Expr::Kind::ScopedPointerType: {
            auto ty = cast<SingleElementTypeBase>(type);

            /// References to `none` are not really well-formed...
            auto elem = ty->elem == Type::Void ? Type::I8 : ty->elem;
            return hlir::ReferenceType::get(Ty(elem));
        }

        case Expr::Kind::ArrayType: {
            auto ty = cast<ArrayType>(type);
            return hlir::ArrayType::get(Ty(ty->elem), ty->dimension().getZExtValue());
        }

        case Expr::Kind::EnumType:
        case Expr::Kind::SugaredType:
        case Expr::Kind::ScopedType: {
            auto ty = cast<SingleElementTypeBase>(type);
            return Ty(ty->elem);
        }

        case Expr::Kind::ClosureType:
            return hlir::ClosureType::get(Ty(cast<ClosureType>(type)->proc_type, true));

        case Expr::Kind::OpaqueType:
            return mlir::LLVM::LLVMStructType::getOpaque(type.mangled_name, mctx);

        case Expr::Kind::ProcType: {
            auto ty = cast<ProcType>(type);
            SmallVector<mlir::Type> params;

            /// Sanity check.
            Assert(not ty->is_smp or not ty->static_chain_parent, "Initialisers canâ€™t be nested procedures");

            /// Add implicit this parameter, if any.
            if (ty->is_smp) params.push_back(hlir::ReferenceType::get(Ty(ty->smp_parent)));

            /// Add regular parameters.
            for (auto& p : ty->parameters) {
                auto param_type = Ty(p.type);
                if (p.passed_by_reference) param_type = hlir::ReferenceType::get(param_type);
                params.push_back(param_type);
            }

            /// Add an extra parameter for the static chain pointer, unless
            /// this is for a closure type, in which case the environment
            /// will already be added anyway.
            if (not for_closure and ty->static_chain_parent) {
                Assert(ty->static_chain_parent->captured_locals_type);
                params.push_back(hlir::ReferenceType::get(Ty(ty->static_chain_parent->captured_locals_type)));
            }

            /// To â€˜return voidâ€™, we have to set no return type at all.
            if (not ty->ret_type.yields_value) return mlir::FunctionType::get(mctx, params, {});
            else return mlir::FunctionType::get(mctx, params, Ty(ty->ret_type));
        }

        case Expr::Kind::OptionalType: {
            auto opt = cast<OptionalType>(type);
            if (auto ref = dyn_cast<ReferenceType>(opt->elem))
                return hlir::OptRefType::get(Ty(ref->elem));
            Todo();
        }

        case Expr::Kind::StructType:
        case Expr::Kind::TupleType: {
            using mlir::LLVM::LLVMStructType;
            auto r = cast<RecordType>(type);
            if (auto it = record_types.find(r); it != record_types.end()) return it->second;

            /// Handle recursion.
            if (auto s = dyn_cast<StructType>(r); s and not s->name.empty())
                record_types[s] = LLVMStructType::getIdentified(mctx, s->name);

            /// Collect element types.
            auto range = r->field_types() | vws::transform([&](auto t) { return Ty(t); });
            SmallVector<mlir::Type> elements{range.begin(), range.end()};

            /// Named struct.
            if (auto s = dyn_cast<StructType>(r); s and not s->name.empty()) {
                auto ok = cast<LLVMStructType>(record_types.at(s)).setBody(elements, false);
                if (mlir::failed(ok)) Diag::ICE(
                    ctx,
                    s->location,
                    "Could not convert struct type to HLIR"
                );
            }

            /// Literal struct.
            else {
                record_types[r] = LLVMStructType::getLiteral(
                    mctx,
                    elements,
                    false
                );
            }

            return record_types.at(r);
        }

        case Expr::Kind::Nil:
            Diag::ICE(ctx, type->location, "Nil type has no representation in the IR");

#define SOURCE_AST_EXPR(name) case Expr::Kind::name:
#define SOURCE_AST_TYPE(...)
#include <source/Frontend/AST.def>
            Unreachable("Not a type");
    }

    Unreachable();
}

auto src::CodeGen::UnwindValues(ArrayRef<Expr*> exprs) -> SmallVector<mlir::Value> {
    SmallVector<mlir::Value> vals;
    for (auto e : exprs) {
        if (isa<DeferExpr>(e)) vals.push_back(Generate(e));
        else if (auto l = dyn_cast<LocalDecl>(e)) {
            auto addr = local_vars.at(l);
            auto d = Destroy(Loc(l->location), addr, l->type);
            if (d) vals.push_back(d);
        }
    }
    return vals;
}

/// ===========================================================================
///  Code Generation
/// ===========================================================================
auto src::CodeGen::Generate(src::Expr* expr) -> mlir::Value {
    switch (expr->kind) {
        /// Canâ€™t codegen types.
#define SOURCE_AST_TYPE(name) case Expr::Kind::name:
#define SOURCE_AST_NIL(...)   /// Better error message for nil.
#include <source/Frontend/AST.def>
        Diag::ICE(ctx, expr->location, "Donâ€™t know how to codegen types");

        case Expr::Kind::OverloadSetExpr:
            Diag::ICE(ctx, expr->location, "Unresolved overload set in codegen");

        /// These are no-ops.
        case Expr::Kind::AliasExpr:
        case Expr::Kind::EmptyExpr:
        case Expr::Kind::EnumeratorDecl:
        case Expr::Kind::FieldDecl:
        case Expr::Kind::ModuleRefExpr:
            return {};

        /// A construct expression without a target is meaningless.
        case Expr::Kind::ConstructExpr:
            Diag::ICE(ctx, expr->location, "ConstructExpr without result object");

        /// Nil should always be wrapped in a cast expression.
        case Expr::Kind::Nil:
            Diag::ICE(ctx, expr->location, "Nil has no representation in the IR");

        case Expr::Kind::InvokeExpr: {
            auto e = cast<InvokeExpr>(expr);
            mlir::Value callee;
            SmallVector<mlir::Value> args;

            /// Helper to create a call to a procedure.
            auto CreateCall = [&](mlir::Type type, mlir::LLVM::CConv cc, StringRef proc_name) {
                auto call_op = Create<hlir::CallOp>(
                    Loc(e->location),
                    cast<mlir::FunctionType>(type).getResults(),
                    proc_name,
                    false,
                    cc,
                    args
                );

                /// The operation only has a result if the functionâ€™s
                /// return type is not void.
                return e->type.yields_value ? call_op.getYield() : mlir::Value{};
            };

            /// Emit the object/callee.
            auto m = dyn_cast<MemberAccessExpr>(e->callee);
            if (e->callee->type != Type::MemberProc) callee = Generate(e->callee);
            else {
                /// Sema should ensure that this is an lvalue, if need be by materialising a
                /// temporary. Furthermore, Sema sets the object as the first argument, so we
                /// donâ€™t need to emit it here, unless this is an smp (an smp that is called
                /// implicitly is never a member procedure call, so if a member call calls an
                /// smp, itâ€™s because the user actually wrote e.g. `.init`).
                Assert(m->object->is_lvalue, "Member function calls on rvalues are not supported");
                callee = Generate(m->field);
                if (m->field->is_smp) args.push_back(Generate(m->object));
            }

            /// Emit args.
            for (auto a : e->args) args.push_back(Generate(a));

            /// Handle member function calls.
            if (e->callee->type == Type::MemberProc) {
                auto proc = dyn_cast<mlir::func::ConstantOp>(callee.getDefiningOp());
                auto type = cast<ProcType>(m->field->type.desugared);
                return CreateCall(Ty(type), ConvertCC(type->call_conv), proc.getValue());
            }

            /// If the callee is a procedure decl, call it directly.
            if (auto proc = dyn_cast<mlir::func::ConstantOp>(callee.getDefiningOp())) {
                /// If the callee takes a static chain pointer, retrieve
                /// it and add it to the argument list.
                auto type = cast<ProcType>(e->callee->type.desugared);
                if (auto chain = type->static_chain_parent) args.push_back(GetStaticChainPointer(chain));
                return CreateCall(proc.getType(), ConvertCC(type->call_conv), proc.getValue());
            }

            /// If the callee is a closure, then use a special operation for that.
            if (auto c = dyn_cast<ClosureType>(e->callee->type)) {
                auto call_op = Create<hlir::InvokeClosureOp>(
                    Loc(e->location),
                    e->type.yields_value ? mlir::TypeRange{Ty(e->type)} : mlir::TypeRange{},
                    callee,
                    ConvertCC(c->proc_type->call_conv),
                    args
                );

                /// The operation only has a result if the functionâ€™s
                /// return type is not void.
                return e->type.yields_value ? call_op.getResult() : mlir::Value{};
            }

            Unreachable("Indirect calls must be closure calls.");
        }

        case Expr::Kind::InvokeBuiltinExpr: {
            auto i = cast<InvokeBuiltinExpr>(expr);
            switch (i->builtin) {
                /// Delete calls the destructor of an object.
                case Builtin::Destroy: {
                    std::ignore = Generate(i->args[0]);
                    auto var = cast<LocalRefExpr>(i->args[0])->decl;
                    EndLifetime(var);
                    return {};
                }

                case Builtin::Memcpy: {
                    Todo();
                }

                case Builtin::New: {
                    return Create<hlir::NewOp>(
                        Loc(i->location),
                        hlir::ReferenceType::get(Ty(i->type))
                    );
                }
            }

            Unreachable();
        }

        case Expr::Kind::MaterialiseTemporaryExpr: {
            auto m = cast<MaterialiseTemporaryExpr>(expr);
            auto loc = Loc(m->location);
            auto align = m->type.align(ctx);
            auto tmp = Create<hlir::LocalOp>(loc, Ty(m->type), align.value());
            Construct(loc, tmp, align, m->ctor);
            return tmp;
        }

        case Expr::Kind::AssignExpr: {
            auto a = cast<AssignExpr>(expr);
            auto loc = Loc(a->location);
            auto align = a->lvalue->type.align(ctx);
            auto lval = Generate(a->lvalue);
            Construct(loc, lval, align, a->ctor);
            return lval;
        }

        case Expr::Kind::ParenExpr: {
            auto p = cast<ParenExpr>(expr);
            return Generate(p->expr);
        }

        case Expr::Kind::DeclRefExpr: {
            auto e = cast<DeclRefExpr>(expr);
            return EmitReference(Loc(e->location), e->decl);
        }

        case Expr::Kind::LocalRefExpr: {
            auto var = cast<LocalRefExpr>(expr);

            /// Easy case: the variable weâ€™re accessing is in the same
            /// scope as the reference.
            if (var->parent == var->decl->parent) {
                Assert(local_vars.contains(var->decl));
                return local_vars.at(var->decl);
            }

            /// This is the complicated one. We need to retrieve the
            /// address of this variable (note that this is an lvalue!)
            /// via the static chain.
            ///
            /// Get the frame pointer of the procedure containing
            /// the variable declaration.
            auto& locals = var->decl->parent->captured_locals;
            auto var_index = std::distance(locals.begin(), rgs::find(locals, var->decl));
            return Create<hlir::StructGEPOp>(
                Loc(var->location),
                GetStaticChainPointer(var->decl->parent),
                var_index + var->decl->parent->nested
            );
        }

        case Expr::Kind::MemberAccessExpr: {
            /// Emit the base object.
            auto e = cast<MemberAccessExpr>(expr);
            auto obj = Generate(e->object);

            /// The object may be an lvalue; if so, yield the address
            /// rather than loading the entire object.
            if (e->object->is_lvalue) {
                if (isa<StructType>(e->object->type.desugared)) {
                    /// If we get here, this should be a field decl as member
                    /// function calls are handled elsewhere.
                    Assert(isa<FieldDecl>(e->field), "Member access should point to a field");
                    Assert(e->is_lvalue, "Accessing a member of an lvalue should yield an lvalue");
                    Assert(e->field, "Struct field not set for member access");
                    return Create<hlir::StructGEPOp>(
                        Loc(e->location),
                        obj,
                        cast<FieldDecl>(e->field)->index
                    );
                }

                Unreachable(
                    "Unsupported member access on lvalue of type '{}'",
                    e->object->type.str(ctx->use_colours)
                );
            }

            /// Object is an rvalue.
            /// Member of a slice.
            if (isa<SliceType>(e->object->type.desugared)) {
                if (e->member == "data") return Create<hlir::SliceDataOp>(Loc(e->location), obj);
                if (e->member == "size") return Create<hlir::SliceSizeOp>(
                    Loc(e->location),
                    Ty(Type::Int),
                    obj
                );
            }

            Unreachable(
                "Unsupported member access on rvalue of type '{}'",
                e->object->type.str(ctx->use_colours)
            );
        }

        /// The â€˜objectâ€™ is just a scope, so we donâ€™t emit anything for it.
        case Expr::Kind::ScopeAccessExpr: {
            auto sa = cast<ScopeAccessExpr>(expr);
            return EmitReference(Loc(sa->location), sa->resolved);
        }

        case Expr::Kind::CastExpr: {
            auto c = cast<CastExpr>(expr);

            /// Emit the operand.
            mlir::Value operand;
            if (not isa<Nil>(c->operand)) operand = Generate(c->operand);

            /// Note that some of the casts perform the same operation,
            /// but they are logically distinct in that they yield different
            /// types and value categories at the AST level.
            switch (c->cast_kind) {
                /// Load a value or a reference.
                case CastKind::LValueRefToLValue:
                case CastKind::LValueToRValue:
                    Assert(c->operand->is_lvalue);
                    return Create<hlir::LoadOp>(Loc(c->location), operand);

                /// Reference <-> LValue; Nop
                ///
                /// These are logical operations only and no-ops
                /// at the IR level.
                case CastKind::ReferenceToLValue:
                case CastKind::LValueToReference:
                    return operand;

                /// Technically a no-op, but the type is different.
                case CastKind::ArrayToElemRef:
                    return Create<hlir::ArrayDecayOp>(Loc(c->location), operand);

                /// Test if an optional is nil.
                case CastKind::OptionalNilTest: {
                    auto opt = cast<OptionalType>(c->operand->type);

                    /// Compare optional references against null.
                    if (isa<ReferenceType>(opt->elem)) {
                        auto nil = Create<hlir::NilOp>(Loc(c->operand->location), Ty(opt->elem));
                        return Create<hlir::PointerNeOp>(
                            Loc(c->location),
                            operand,
                            nil
                        );
                    }

                    Todo();
                }

                /// Access the value of an optional.
                case CastKind::OptionalUnwrap: {
                    auto opt = cast<OptionalType>(c->operand->type);

                    /// No-op for optional references.
                    if (isa<ReferenceType>(opt->elem)) {
                        auto res = c->is_lvalue
                                     ? hlir::ReferenceType::get(Ty(opt->elem))
                                     : Ty(opt->elem);

                        return Create<hlir::BitCastOp>(
                            Loc(c->location),
                            res,
                            operand
                        );
                    }

                    Todo();
                }

                /// Create an optional from a value.
                case CastKind::OptionalWrap: {
                    auto opt = cast<OptionalType>(c->type);

                    /// No-op for optional references. This is always an rvalue.
                    if (isa<ReferenceType>(opt->elem)) return Create<hlir::BitCastOp>(
                        Loc(c->location),
                        Ty(c->type),
                        operand
                    );

                    Todo();
                }

                /// Proper casts are all handled the same.
                case CastKind::Implicit:
                case CastKind::Soft:
                case CastKind::Hard:
                    return GenerateConvertingCast(c, operand);
            }

            Unreachable();
        }

        case Expr::Kind::ConstExpr: {
            auto c = cast<ConstExpr>(expr);
            Assert(c->value.is_int(), "Can only generate integer constant expressions");
            return CreateInt(Loc(c->location), c->value.as_int(), c->type);
        };

        case Expr::Kind::DeferExpr: {
            auto d = cast<DeferExpr>(expr);
            if (defers.contains(d)) return defers[d];
            auto op = defers[d] = Create<hlir::DeferOp>(Loc(expr->location));
            mlir::OpBuilder::InsertionGuard guard{builder};
            builder.setInsertionPointToEnd(&op.getBody().front());
            std::ignore = Generate(d->expr);
            if (not Closed(builder.getBlock())) Create<hlir::YieldOp>(
                builder.getUnknownLoc(),
                mlir::Value{},
                mlir::ValueRange{}
            );
            return op;
        }

        case Expr::Kind::LoopControlExpr: {
            auto l = cast<LoopControlExpr>(expr);
            const auto loc = Loc(expr->location);

            /// Emit the branch.
            Create<hlir::DirectBrOp>(
                loc,
                l->is_continue ? l->target->continue_block : l->target->break_block,
                UnwindValues(l->unwind)
            );
            return {};
        }

        case Expr::Kind::GotoExpr: {
            auto g = cast<GotoExpr>(expr);

            Create<hlir::DirectBrOp>(
                Loc(g->location),
                g->target->block,
                UnwindValues(g->unwind)
            );
            return {};
        }

        case Expr::Kind::LabelExpr: {
            auto l = cast<LabelExpr>(expr);

            /// Insert the block that weâ€™ve already created for this label.
            if (l->used) {
                Create<mlir::cf::BranchOp>(
                    Loc(l->location),
                    l->block
                );

                builder.getBlock()->getParent()->push_back(l->block);
                builder.setInsertionPointToEnd(l->block);
            }

            /// Emit the labelled expression.
            return Generate(l->expr);
        }

        /// Nothing to do here other than emitting the underlying decl.
        case Expr::Kind::ExportExpr: {
            auto e = cast<ExportExpr>(expr);

            /// Do not attempt to emit anything here, but make sure we
            /// havenâ€™t changed our mind about that either.
            Assert((isa<ProcDecl, StructType>(e->expr)), "Invalid export");
            return {};
        }

        case Expr::Kind::ReturnExpr: {
            auto r = cast<ReturnExpr>(expr);
            mlir::Value ret;
            if (r->value) ret = Generate(r->value);

            /// Return the value.
            if (not Closed()) {
                Create<hlir::ReturnOp>(
                    Loc(r->location),
                    ret,
                    UnwindValues(r->unwind)
                );
            }
            return {};
        }

        /// There is no AssertOp in HLIR since assertions require control flow.
        case Expr::Kind::AssertExpr: {
            auto a = cast<AssertExpr>(expr);

            /// Ignore static assertions.
            if (a->is_static) return {};

            /// Only emit assertion message if the assertion fails.
            auto cond = Generate(a->cond);
            auto r = builder.getBlock()->getParent();
            auto loc = Loc(a->location);
            auto fail = new mlir::Block;
            auto cont = new mlir::Block;
            Create<mlir::cf::CondBranchOp>(
                loc,
                cond,
                cont,
                fail
            );

            /// Failure case.
            mlir::Value message;
            r->getBlocks().insertAfter(builder.getBlock()->getIterator(), fail);
            builder.setInsertionPointToEnd(fail);

            /// Emit message.
            if (a->msg) message = Generate(a->msg);
            else {
                message = Create<hlir::NilOp>(
                    loc,
                    hlir::SliceType::get(Ty(Type::I8))
                );
            }

            /// export proc __src_assert_fail(
            ///     i8[] cond,
            ///     i8[] message,
            ///     i8[] file,
            ///     int line,
            ///     int col
            /// )
            auto lc = a->location.seek_line_column(ctx);
            auto line = Create<mlir::arith::ConstantIntOp>(loc, lc.line, Type::Int.size(ctx).bits());
            auto col = Create<mlir::arith::ConstantIntOp>(loc, lc.col, Type::Int.size(ctx).bits());
            auto cond_str = Generate(a->cond_str);
            auto file_str = Generate(a->file_str);

            mlir::Value args[]{
                cond_str,
                message,
                file_str,
                line,
                col,
            };

            Create<hlir::CallOp>(
                loc,
                mlir::TypeRange{},
                "__src_assert_fail",
                false,
                ConvertCC(CallConv::Source),
                args
            );

            /// Should never return.
            Create<hlir::UnreachableOp>(loc);

            /// Continue as normal.
            r->getBlocks().insertAfter(builder.getBlock()->getIterator(), cont);
            builder.setInsertionPointToEnd(cont);
            return {};
        }

        case Expr::Kind::BlockExpr: {
            auto e = cast<BlockExpr>(expr);
            if (e->exprs.empty()) return {};

            /// Create a scope for the block.
            const bool yields_value = e->type.yields_value;
            auto b = Create<hlir::ScopeOp>(
                Loc(e->location),
                not yields_value ? mlir::Type{}
                : e->is_lvalue   ? hlir::ReferenceType::get(Ty(e->type))
                                 : Ty(e->type)
            );

            /// Associate block with scope op.
            e->scope_op = b;

            /// Insert in scope.
            mlir::OpBuilder::InsertionGuard guard{builder};
            builder.setInsertionPointToEnd(&b.getBody().front());

            /// Emit expressions.
            ///
            /// Note that some expressionsâ€”e.g. ProcDecls are not emitted
            /// at block scope because there is either no point in that,
            /// or really no way of doing so (for instance, how are we
            /// supposed to emit a module reference at block scope?).
            mlir::Value last;
            for (auto s : e->exprs) {
                if (isa< // clang-format off
                    AliasExpr,
                    MemberAccessExpr,
                    ModuleRefExpr,
                    OverloadSetExpr,
                    ProcDecl,
                    TypeBase
                >(s)) continue; // clang-format on
                last = Generate(s);
            }

            /// Determine yield.
            mlir::Value yield;
            if (yields_value) yield = b.getRes();
            if (not Closed(builder.getBlock())) {
                Create<hlir::YieldOp>(
                    Loc(e->location),
                    yields_value ? last : mlir::Value{},
                    UnwindValues(e->unwind)
                );
            }

            return yield;
        }

        case Expr::Kind::StrLitExpr: {
            auto str = cast<StrLitExpr>(expr);

            /// Create the string if it doesnâ€™t already exist.
            hlir::StringOp op;
            if (auto it = string_literals.find(str->string); it != string_literals.end()) {
                op = string_literals.at(str->string.value());
            } else {
                mlir::OpBuilder::InsertionGuard _{builder};
                builder.setInsertionPointToStart(mod->mlir.getBody());
                op = string_literals[str->string.value()] = Create<hlir::StringOp>(
                    builder.getUnknownLoc(),
                    str->string.value_with_null(),
                    APInt(64, u64(string_literals.size()))
                );
            }

            /// Create a global ref to the string data. This returns
            /// a reference to an array of chars.
            auto i8 = mlir::IntegerType::get(mctx, 8);
            auto str_arr = Create<hlir::GlobalRefOp>(
                Loc(str->location),
                hlir::ReferenceType::get(hlir::ArrayType::get(i8, str->string.value_with_null().size())),
                mlir::SymbolRefAttr::get(mctx, fmt::format(".str.data.{}", op.getIndex().getZExtValue()))
            );

            /// Insert a conversion from i8[size]& to i8&.
            auto str_ptr = Create<hlir::ArrayDecayOp>(
                Loc(str->location),
                str_arr
            );

            /// Create an integer holding the string size.
            auto str_size = CreateInt(
                Loc(str->location),
                str->string.size() /// Exclude null terminator.
            );

            /// Create a slice.
            return Create<hlir::LiteralOp>(
                Loc(str->location),
                hlir::SliceType::get(i8),
                str_ptr,
                str_size
            );
        }

        /// Create a bool constant.
        case Expr::Kind::BoolLitExpr: {
            auto e = cast<BoolLitExpr>(expr);
            return Create<mlir::arith::ConstantIntOp>(
                Loc(e->location),
                e->value,
                mlir::IntegerType::get(mctx, 1)
            );
        }

        /// Create an integer constant.
        case Expr::Kind::IntLitExpr: {
            auto e = cast<IntLitExpr>(expr);
            return CreateInt(Loc(e->location), e->value, e->type);
        }

        case Expr::Kind::TupleExpr: Unreachable("Cannot emit tuple literals w/o a result object");
        case Expr::Kind::ArrayLitExpr: Unreachable("Cannot emit array literals w/o a result object");

        case Expr::Kind::TupleIndexExpr: {
            auto t = cast<TupleIndexExpr>(expr);
            Assert(t->object->is_lvalue, "TODO: Emit tuple index on rvalue");
            auto obj = Generate(t->object);
            return Create<hlir::StructGEPOp>(
                Loc(t->location),
                obj,
                t->field->index
            );
        }

        case Expr::Kind::LocalDecl:
        case Expr::Kind::ParamDecl: {
            auto e = cast<LocalDecl>(expr);

            /// If the variable hasnâ€™t already been allocated, do so now.
            AllocateLocalVar(e);

            /// Handle construction.
            Construct(Loc(e->location), local_vars.at(e), e->type.align(ctx), e->ctor);

            /// Returns itself as an lvalue.
            return local_vars.at(e);
        }

        /// If expressions.
        case Expr::Kind::IfExpr: {
            auto e = cast<IfExpr>(expr);

            /// If this is a static if, emit only the branch that was taken.
            if (e->is_static) {
                auto cond = cast<ConstExpr>(e->cond)->value.as_int().getBoolValue();
                if (cond) return Generate(e->then);
                if (e->else_) return Generate(e->else_);
                return {};
            }

            /// Emit the condition.
            auto cond = Generate(e->cond);

            /// Create the blocks that we need.
            bool has_yield = e->type.yields_value;
            auto cond_block = builder.getBlock();
            auto region = cond_block->getParent();
            auto then = new mlir::Block;
            auto join = e->type.is_noreturn ? nullptr : new mlir::Block;
            auto else_ = e->else_ ? new mlir::Block : join;
            auto if_loc = Loc(e->location);

            /// Add an argument to the join block if the expression
            /// yields a value.
            if (has_yield) {
                Assert(join);
                auto ty = Ty(e->type);
                if (e->is_lvalue) ty = hlir::ReferenceType::get(ty);
                join->addArgument(ty, if_loc);
            }

            /// Emit the conditional branch.
            Create<mlir::cf::CondBranchOp>(if_loc, cond, then, else_);

            /// Helper to emit a branch.
            auto EmitBranch = [&](Expr* expr, mlir::Block* block) {
                Attach(region, block);
                builder.setInsertionPointToEnd(block);
                auto yield = Generate(expr);
                if (join) Create<mlir::cf::BranchOp>(
                    if_loc,
                    join,
                    has_yield ? yield : mlir::ValueRange{}
                );
            };

            /// Emit the then and else branches.
            EmitBranch(e->then, then);
            if (e->else_) EmitBranch(e->else_, else_);

            /// Finally, resume inserting in the join block.
            if (join) {
                Attach(region, join);
                builder.setInsertionPointToEnd(join);
                if (has_yield) return join->getArgument(0);
            }
            return {};
        }

        case Expr::Kind::WhileExpr: {
            auto w = cast<WhileExpr>(expr);

            /// Create a new block for the condition so we can branch
            /// to it and emit the condition there.
            auto region = builder.getBlock()->getParent();
            w->continue_block = Attach(region, new mlir::Block);
            Create<mlir::cf::BranchOp>(Loc(w->location), w->continue_block);
            builder.setInsertionPointToEnd(w->continue_block);
            auto cond = Generate(w->cond);

            /// Emit the branch to the body.
            auto body = Attach(region, new mlir::Block);
            w->break_block = new mlir::Block;
            Create<mlir::cf::CondBranchOp>(Loc(w->location), cond, body, w->break_block);

            /// Emit the body.
            builder.setInsertionPointToEnd(body);
            std::ignore = Generate(w->body);
            Create<mlir::cf::BranchOp>(Loc(w->location), w->continue_block);

            /// Insert the join block and continue inserting there.
            Attach(region, w->break_block);
            builder.setInsertionPointToEnd(w->break_block);
            return {};
        }

        /// Emit a for-in loop.
        ///
        /// If we are not iterating in reverse, this will emit the
        /// logical equivalent of:
        ///
        /// \code
        /// for (int __i = 0, __size = range.size; __i < __size; __i++) {
        ///     var iter = lvalue to range.data + __i;
        ///     <body>
        /// }
        /// \endcode
        ///
        /// If we are iterating in reverse, this will emit the logical
        /// equivalent of:
        ///
        /// \code
        /// for (int __i = size; __i > 0; __i--) {
        ///     var iter = lvalue to range.data + __i - 1;
        ///     <body>
        /// }
        /// \endcode
        case Expr::Kind::ForInExpr: {
            auto f = cast<ForInExpr>(expr);
            mlir::Value range;

            /// Emit the range, but not the iteration variable, since that
            /// one requires special handling as itâ€™s not actually a variable.
            if (isa<SliceType>(f->range->type)) {
                range = Generate(f->range);
            }

            /// Emit the array. It must be an lvalue.
            else if (auto arr = dyn_cast<ArrayType>(f->range->type)) {
                Assert(f->range->is_lvalue);
                range = CreateSliceFromArray(Loc(f->range->location), arr, Generate(f->range));
            }

            /// Donâ€™t know what to do w/ this.
            else {
                Diag::ICE(
                    ctx,
                    f->range->location,
                    "Type '{}' is not iterable",
                    f->range->type.str(ctx->use_colours)
                );
            }

            /// Get the size of the range.
            mlir::Value size = Create<hlir::SliceSizeOp>(
                builder.getUnknownLoc(),
                Int,
                range
            );

            /// Create the index used for the iteration. We just store the index
            /// in a block argument since itâ€™s not exposed anyway.
            auto zero = CreateInt(Loc(f->location), 0);
            auto region = builder.getBlock()->getParent();

            /// This needs to be a new block so we can branch to it.
            auto cond_block = Attach(region, new mlir::Block);
            cond_block->addArgument(Int, builder.getUnknownLoc());
            Create<mlir::cf::BranchOp>(
                Loc(f->location),
                cond_block,
                mlir::ValueRange{f->reverse ? size : zero}
            );

            /// Test the condition.
            using Pred = mlir::arith::CmpIPredicate;
            builder.setInsertionPointToEnd(cond_block);
            auto should_continue = Create<mlir::arith::CmpIOp>(
                builder.getUnknownLoc(),
                f->reverse ? Pred::ugt : Pred::ult,
                cond_block->getArgument(0),
                f->reverse ? zero : size
            );

            /// Branch depending on the condition. Also creat, but do not insert,
            /// the continue and break blocks here since any continue/break in
            /// the loop body will have to branch to one of them.
            auto body = Attach(region, new mlir::Block);
            f->continue_block = new mlir::Block;
            f->break_block = new mlir::Block;
            Create<mlir::cf::CondBranchOp>(
                builder.getUnknownLoc(),
                should_continue,
                body,
                f->break_block
            );

            /// Before emitting the body, get the slice data pointer and create
            /// a gep to the current index for the loop variable.
            builder.setInsertionPointToEnd(body);
            auto data = Create<hlir::SliceDataOp>(builder.getUnknownLoc(), range);

            /// Offset is `i` if weâ€™re iterating forward and `i - 1` otherwise.
            mlir::Value offset = cond_block->getArgument(0);
            if (f->reverse) {
                offset = Create<mlir::arith::SubIOp>(
                    builder.getUnknownLoc(),
                    offset,
                    CreateInt(Loc(f->location), 1)
                );
            }

            if (f->index) local_vars[f->index] = cond_block->getArgument(0);
            if (f->iter) {
                auto iter = Create<hlir::OffsetOp>(builder.getUnknownLoc(), data, offset);
                local_vars[f->iter] = iter;
            }

            /// Dew it.
            std::ignore = Generate(f->body);

            /// Increment/decrement the index and go back to the condition. This is also
            /// where we branch to in case of a continue.
            Attach(region, f->continue_block);
            if (not Closed(builder.getBlock())) Create<mlir::cf::BranchOp>(
                builder.getUnknownLoc(),
                f->continue_block
            );

            mlir::Value inc;
            builder.setInsertionPointToEnd(f->continue_block);
            if (f->reverse) {
                inc = Create<mlir::arith::SubIOp>(
                    builder.getUnknownLoc(),
                    cond_block->getArgument(0),
                    CreateInt(Loc(f->location), 1)
                );
            } else {
                inc = Create<mlir::arith::AddIOp>(
                    builder.getUnknownLoc(),
                    cond_block->getArgument(0),
                    CreateInt(Loc(f->location), 1)
                );
            }

            Create<mlir::cf::BranchOp>(
                builder.getUnknownLoc(),
                cond_block,
                mlir::ValueRange{inc}
            );

            /// Insert the break block and continue inserting there.
            Attach(region, f->break_block);
            builder.setInsertionPointToEnd(f->break_block);
            return {};
        }

        case Expr::Kind::WithExpr: {
            auto w = cast<WithExpr>(expr);

            /// Emit the object.
            std::ignore = Generate(w->object);

            /// Emit the body if there is one.
            if (w->body) return Generate(w->body);
            return {};
        }

        case Expr::Kind::UnaryPrefixExpr: {
            auto u = cast<UnaryPrefixExpr>(expr);
            auto op = Generate(u->operand);
            switch (u->op) {
                default: Unreachable("Invalid unary operator: {}", Spelling(u->op));

                /// Negation.
                case Tk::Not: return Create<hlir::NotOp>(Loc(u->location), op);

                /// Dereference.
                case Tk::Star: return Create<hlir::LoadOp>(Loc(u->location), op);
            }
        }

        case Expr::Kind::SubscriptExpr: {
            auto f = cast<SubscriptExpr>(expr);
            if (not isa<SliceType>(f->object->type)) Diag::ICE(
                ctx,
                f->object->location,
                "Sorry, we only support subscripting slices for now."
            );

            auto index = Generate(f->index);
            auto object = Generate(f->object);
            auto ptr = Create<hlir::SliceDataOp>(Loc(f->location), object);
            return Create<hlir::OffsetOp>(Loc(f->location), ptr, index);
        }

        case Expr::Kind::BinaryExpr: {
            auto b = cast<BinaryExpr>(expr);
            if (b->op == Tk::And or b->op == Tk::Or) {
                auto lhs = Generate(b->lhs);
                auto loc = Loc(b->location);
                auto rhs = new mlir::Block;
                auto res = new mlir::Block;
                res->addArgument(Ty(Type::Bool), loc);

                /// Then-block is rhs, else-block is res w/ false.
                if (b->op == Tk::And) {
                    Create<mlir::cf::CondBranchOp>(
                        loc,
                        lhs,
                        rhs,
                        mlir::ValueRange{},
                        res,
                        mlir::ValueRange{lhs}
                    );
                }

                /// Then-block is res w/ true, else-block is rhs.
                else {
                    Create<mlir::cf::CondBranchOp>(
                        loc,
                        lhs,
                        res,
                        mlir::ValueRange{lhs},
                        rhs,
                        mlir::ValueRange{}
                    );
                }

                /// Emit RHS.
                auto& r = builder.getBlock()->getParent()->getBlocks();
                r.insertAfter(builder.getBlock()->getIterator(), rhs);
                builder.setInsertionPointToEnd(rhs);
                auto rhs_val = Generate(b->rhs);
                Create<mlir::cf::BranchOp>(
                    loc,
                    res,
                    rhs_val
                );

                /// Join block.
                r.insertAfter(builder.getBlock()->getIterator(), res);
                builder.setInsertionPointToEnd(res);
                return res->getArgument(0);
            }

            switch (b->op) {
                using mlir::arith::CmpIPredicate;
                using namespace hlir;
                default: Unreachable("Invalid binary operator: {}", Spelling(b->op));

                /// Arithmetic and bitwise operators.
                case Tk::Land: return GenerateBinOp<AndOp>(b);
                case Tk::Lor: return GenerateBinOp<OrOp>(b);
                case Tk::Minus: return GenerateBinOp<SubOp>(b);
                case Tk::Percent: return GenerateBinOp<RemOp>(b);
                case Tk::Plus: return GenerateBinOp<AddOp>(b);
                case Tk::ShiftLeft: return GenerateBinOp<ShlOp>(b);
                case Tk::ShiftRight: return GenerateBinOp<SarOp>(b);
                case Tk::ShiftRightLogical: return GenerateBinOp<ShrOp>(b);
                case Tk::Slash: return GenerateBinOp<DivOp>(b);
                case Tk::Star: return GenerateBinOp<MulOp>(b);
                case Tk::StarStar: return GenerateBinOp<ExpOp>(b);
                case Tk::Xor: return GenerateBinOp<XorOp>(b);

                /// Comparison operators.
                case Tk::EqEq: return GenerateCmpOp<EqOp>(b);
                case Tk::Ge: return GenerateCmpOp<GeOp>(b);
                case Tk::Gt: return GenerateCmpOp<GtOp>(b);
                case Tk::Le: return GenerateCmpOp<LeOp>(b);
                case Tk::Lt: return GenerateCmpOp<LtOp>(b);
                case Tk::Neq: return GenerateCmpOp<NeOp>(b);

                /// Compound assignment.
                case Tk::MinusEq: return GenerateAssignBinOp<SubOp>(b);
                case Tk::PercentEq: return GenerateAssignBinOp<RemOp>(b);
                case Tk::PlusEq: return GenerateAssignBinOp<AddOp>(b);
                case Tk::ShiftLeftEq: return GenerateAssignBinOp<ShlOp>(b);
                case Tk::ShiftRightEq: return GenerateAssignBinOp<SarOp>(b);
                case Tk::ShiftRightLogicalEq: return GenerateAssignBinOp<ShrOp>(b);
                case Tk::SlashEq: return GenerateAssignBinOp<DivOp>(b);
                case Tk::StarEq: return GenerateAssignBinOp<MulOp>(b);
                case Tk::StarStarEq: return GenerateAssignBinOp<ExpOp>(b);

                /// Assignment and reference binding.
                case Tk::Assign:
                case Tk::RDblArrow: {
                    auto lhs = Generate(b->lhs);
                    auto rhs = Generate(b->rhs);
                    Create<hlir::StoreOp>(
                        Loc(b->location),
                        lhs,
                        rhs,
                        b->type.align(ctx).value()
                    );

                    /// Yields lhs as lvalue.
                    return lhs;
                }
            }
        }

        /// This is the first parameter of the current function.
        case Expr::Kind::ImplicitThisExpr:
            return cast<hlir::FuncOp>(curr_proc->mlir_func).getImplicitThis();

        /// It is an error to have a ProcDecl directly referenced by anything that
        /// is not a DeclRefExpr or ScopeAccess. The reason for this is that we need
        /// to emit a ConstantOp for each use of the procedure, but we canâ€™t do that
        /// every time itâ€™s used if itâ€™s the same procedure node.
        case Expr::Kind::ProcDecl: Diag::ICE(
            ctx,
            expr->location,
            "ProcDecl may only be â€˜Generate()â€™d by a call to EmitReference()."
        );
    }

    Unreachable();
}

template <typename Op>
auto src::CodeGen::GenerateAssignBinOp(src::BinaryExpr* b) -> mlir::Value {
    auto lhs = Generate(b->lhs);
    auto rhs = Generate(b->rhs);

    /// LHS is an lvalue, so load it first. Perform the binary
    /// operation and store the result back into the lvalue; the
    /// yield of the entire expression is the lvalue.
    auto lhs_val = Create<hlir::LoadOp>(Loc(b->lhs->location), lhs);
    auto align = b->type.align(ctx).value();
    auto res = Create<Op>(Loc(b->location), lhs_val, rhs);
    Create<hlir::StoreOp>(Loc(b->location), lhs, res, align);
    return res;
}

template <typename Op>
auto src::CodeGen::GenerateBinOp(BinaryExpr* b) -> mlir::Value {
    auto lhs = Generate(b->lhs);
    auto rhs = Generate(b->rhs);
    return Create<Op>(Loc(b->location), lhs, rhs);
}

template <typename Op>
auto src::CodeGen::GenerateCmpOp(BinaryExpr* b) -> mlir::Value {
    auto lhs = Generate(b->lhs);
    auto rhs = Generate(b->rhs);
    return Create<Op>(Loc(b->location), Ty(b->type), lhs, rhs);
}

auto src::CodeGen::GenerateConvertingCast(CastExpr* c, mlir::Value operand) -> mlir::Value {
    auto from_type = c->operand->type.desugared_underlying;
    auto to_type = c->type.desugared_underlying;

    /// Create a nil of the target type.
    if (isa<Nil>(from_type)) return Create<hlir::NilOp>(Loc(c->location), Ty(to_type));

    /// No-op.
    if (from_type == to_type) return operand;

    /// Procedure to closure casts.
    if (isa<ProcType>(from_type) and isa<ClosureType>(to_type)) {
        auto proc = operand.getDefiningOp<mlir::func::ConstantOp>();
        auto proc_type = cast<ProcType>(from_type);

        /// If the procedure is a nested function that takes a static
        /// chain, retrieve the appropriate chain pointer.
        if (proc_type->static_chain_parent) {
            auto chain = GetStaticChainPointer(proc_type->static_chain_parent);
            return Create<hlir::MakeClosureOp>(
                Loc(c->location),
                proc.getValue(),
                Ty(to_type),
                chain
            );
        }

        /// Otherwise, leave the data pointer empty; the backend will
        /// set it to null during lowering.
        return Create<hlir::MakeClosureOp>(
            Loc(c->location),
            proc.getValue(),
            Ty(to_type)
        );
    }

    /// Enum/integer-to-enum/integer casts.
    if (from_type.is_int(true) and to_type.is_int(true)) {
        auto from_size = from_type.size(ctx);
        auto to_size = to_type.size(ctx);

        /// Truncation.
        if (from_size > to_size) {
            /// Casts to bool never actually truncate, but are instead
            /// equivalent to != 0. Note that that only applies to bool,
            /// not i1!
            if (to_type == Type::Bool) {
                auto int_type = mlir::IntegerType::get(mctx, unsigned(from_size.bits()));
                auto zero = Create<mlir::arith::ConstantOp>(
                    Loc(c->location),
                    int_type,
                    mlir::IntegerAttr::get(int_type, 0)
                );

                return Create<mlir::arith::CmpIOp>(
                    Loc(c->location),
                    mlir::IntegerType::get(mctx, 1),
                    mlir::arith::CmpIPredicate::ne,
                    operand,
                    zero
                );
            }

            return Create<mlir::arith::TruncIOp>(
                Loc(c->location),
                mlir::IntegerType::get(mctx, unsigned(to_size.bits())),
                operand
            );
        }

        /// Extension.
        if (from_size < to_size) {
            /// Since all of our integers are signed, we always use sign
            /// extension, except that, if weâ€™re extending an i1, we use
            /// zero-extension, as in case of an i1 with the value 1 (true)
            /// sign-extension would yield -1 instead of 1.
            if (from_size.bits() == 1) {
                return Create<mlir::arith::ExtUIOp>(
                    Loc(c->location),
                    mlir::IntegerType::get(mctx, unsigned(to_size.bits())),
                    operand
                );
            }

            return Create<mlir::arith::ExtSIOp>(
                Loc(c->location),
                mlir::IntegerType::get(mctx, unsigned(to_size.bits())),
                operand
            );
        }

        /// No-op.
        return operand;
    }

    /// Array-to-slice casts.
    if (isa<ArrayType>(from_type) and isa<SliceType>(to_type)) {
        Assert(c->operand->is_lvalue);
        return CreateSliceFromArray(
            Loc(c->location),
            cast<ArrayType>(from_type),
            operand
        );
    }

    Diag::ICE(
        ctx,
        c->location,
        "Unsupported cast from {} to {} in backend",
        c->operand->type.str(true),
        c->type.str(true)
    );
}

void src::CodeGen::GenerateModule() {
    mctx->loadDialect<hlir::HLIRDialect>();

    /// Initialise MLIR module.
    mod->mlir_module_op = mlir::ModuleOp::create(
        Loc(mod->module_decl_location),
        mod->name.empty() ? "__exe__" : mod->name
    );

    /*    /// Set size of pointer.
        auto ptr_size = mlir::DataLayoutEntryAttr::get(
            hlir::ReferenceType::get(mlir::IntegerType::get(mctx, 1)),   /// Elem is irrelevant.
            mlir::IntegerAttr::get(mlir::IntegerType::get(mctx, 64), 64) /// FIXME: use context.
        );

        /// Crate data layout.
        mod->mlir->setAttr(
            mlir::DLTIDialect::kDataLayoutAttrName,
            mlir::DataLayoutSpecAttr::get(mctx, {ptr_size})
        );*/

    /// Codegen imports.
    builder.setInsertionPointToEnd(mod->mlir.getBody());
    for (auto& m : mod->imports) {
        for (auto& exp : m.mod->exports) {
            for (auto e : exp.second) {
                if (auto p = dyn_cast<ProcDecl>(e)) {
                    GenerateProcedure(p);
                } else if (isa<StructType>(e)) {
                    /// Nop.
                } else {
                    e->print(false);
                    Unreachable("Invalid import");
                }
            }
        }
    }

    /// Codegen functions.
    for (auto f : mod->functions) {
        builder.setInsertionPointToEnd(mod->mlir.getBody());
        GenerateProcedure(f);
    }

    /// Delete all function constants.
    mod->mlir.getBodyRegion().walk([](mlir::Operation* op) {
        if (isa<mlir::func::ConstantOp>(op)) op->erase();
    });

    /// Verify the IR.
    if (not no_verify and not mlir::succeeded(mod->mlir.verify()))
        Diag::ICE(ctx, mod->module_decl_location, "Module verification failed");
}

void src::CodeGen::GenerateProcedure(ProcDecl* proc) {
    tempset curr_proc = proc;

    /// Note that different modules, particularly C++ headers, may
    /// export the same procedures, so take care to only define them
    /// at most once.
    if (declared_procedures.contains(proc->mangled_name)) {
        auto func_op = declared_procedures[proc->mangled_name];

        /// If this is a declaration, just set the func op.
        if (not proc->body) {
            proc->mlir_func = func_op;
            return;
        }

        /// We canâ€™t convert a declaration to a definition.
        Unreachable(
            "Procedure '{}' cannot be defined after it has been declared",
            proc->mangled_name
        );
    }

    /// Create the function.
    auto ptype = cast<ProcType>(proc->type);
    auto ty = Ty(ptype);
    auto func = Create<hlir::FuncOp>(
        Loc(proc->location),
        proc->mangled_name,
        ConvertLinkage(proc->linkage),
        ConvertCC(ptype->call_conv),
        ty.cast<mlir::FunctionType>(),
        proc->is_smp,
        ptype->variadic
    );

    /// Associate the function with the procedure.
    proc->mlir_func = func;
    declared_procedures[proc->mangled_name] = func;

    /// If there is no body, drop the entry block.
    if (not proc->body) {
        func.eraseBody();
        func.setPrivate();
        return;
    }

    /// Entry block must be created first so we can access parameter values.
    local_vars.clear();
    defers.clear();
    builder.setInsertionPointToEnd(&func.front());

    /// Perform static construction.
    if (proc == mod->top_level_func) {
        if (mod->is_logical_module) {
            /// Create init guard variable.
            auto name = mod->init_guard_name();
            auto uloc = builder.getUnknownLoc();
            auto int32 = Ty(Type::I32);
            mlir::LLVM::GlobalOp init_guard;
            {
                mlir::OpBuilder::InsertionGuard guard{builder};
                builder.setInsertionPointToEnd(&cast<mlir::ModuleOp>(mod->mlir_module_op).getBodyRegion().back());
                init_guard = Create<mlir::LLVM::GlobalOp>(
                    uloc,
                    int32,
                    false,
                    mlir::LLVM::Linkage::Private,
                    name,
                    mlir::IntegerAttr::get(int32, 0),
                    Type::I32.align(ctx).value()
                );
            }

            /// Create init guard check.
            auto ref = Create<mlir::LLVM::AddressOfOp>(uloc, init_guard);
            auto one = Create<mlir::LLVM::ConstantOp>(uloc, int32, mlir::IntegerAttr::get(int32, 1));
            auto inc = Create<mlir::LLVM::AtomicRMWOp>(
                uloc,
                mlir::LLVM::AtomicBinOp::add,
                ref,
                one,
                mlir::LLVM::AtomicOrdering::acq_rel
            );

            /// Init if the old value was zero.
            auto zero = Create<mlir::LLVM::ConstantOp>(uloc, int32, mlir::IntegerAttr::get(int32, 0));
            auto cond = Create<mlir::arith::CmpIOp>(
                uloc,
                mlir::arith::CmpIPredicate::eq,
                inc.getResult(),
                zero
            );

            auto ret = new mlir::Block;
            auto init = new mlir::Block;
            Create<mlir::cf::CondBranchOp>(
                uloc,
                cond.getResult(),
                init,
                ret
            );

            builder.getBlock()->getParent()->push_back(ret);
            builder.setInsertionPointToEnd(ret);
            Create<hlir::ReturnOp>(uloc);

            builder.getBlock()->getParent()->push_back(init);
            builder.setInsertionPointToEnd(init);
        }

        /// Initialise imported modules.
        for (auto& i : mod->imports) {
            if (i.is_cxx_header) continue;
            Create<hlir::CallOp>(
                builder.getUnknownLoc(),
                mlir::TypeRange{},
                i.mod->module_initialiser_name(),
                false,
                ConvertCC(CallConv::Source)
            );
        }
    }

    /// Create, but do not insert, blocks for all labels that are actually branched to.
    for (auto& [_, l] : proc->labels)
        if (l->used)
            l->block = new mlir::Block;

    /// Perform the transformations required to make local variables
    /// declared in this procedure accessible to its nested procedures.
    InitStaticChain(proc, func);

    /// Create local variables for parameters.
    for (auto [i, p] : llvm::enumerate(proc->params)) {
        /// For by-reference parameters, we simply use that reference
        /// as the address of the variable instead of creating a stack
        /// variable for it.
        ///
        /// Similarly, 'in' parameters that are passed by value can also
        /// just be used directly since they are rvalues, not lvalues.
        ///
        /// However, 'in' parameters that are passed by reference must be
        /// loaded once.
        if (p->info->passed_by_reference or p->info->intent == Intent::In) {
            if (p->captured) Diag::ICE("Sorry, capturing by-reference parameters is not yet supported");
            auto arg = func.getExplicitArgument(u32(i));
            if (p->info->intent == Intent::In and p->info->passed_by_reference)
                arg = Create<hlir::LoadOp>(Loc(p->location), arg);
            local_vars[p] = arg;
            continue;
        }

        /// By-value parameter.
        AllocateLocalVar(p);

        /// TODO: What was this todo about again?
        /// TODO: Handle self-referential types.

        /// Store the initial parameter value in the variable.
        Create<hlir::StoreOp>(
            Loc(p->location),
            local_vars.at(p),
            func.getExplicitArgument(u32(i)),
            p->type.align(ctx).value()
        );
    }

    /// Emit the body.
    auto ret = Generate(proc->body);

    /// Insert a return expression at the end if there isnâ€™t already one.
    ///
    /// Note: No need to worry about deferred expressions here or anything since
    /// that has already been taken care of by the code that emits the body.
    if (func.back().empty() or not func.back().back().hasTrait<mlir::OpTrait::IsTerminator>()) {
        /// Function returns void.
        if (proc->ret_type == Type::Void) {
            Create<hlir::ReturnOp>(Loc(proc->location));
        }

        /// Function does not return, or all paths return a value, but there
        /// is no return expression at the very end.
        else if (proc->ret_type == Type::NoReturn or not proc->body->implicit) {
            Create<hlir::UnreachableOp>(Loc(proc->location));
        }

        /// Function is a `= <expr>` function that returns its body.
        else {
            Assert(ret, "Inferred procedure body must yield a value");
            Create<hlir::ReturnOp>(Loc(proc->location), ret);
        }
    }
}
